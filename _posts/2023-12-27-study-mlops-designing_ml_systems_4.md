---
layout: post
title:  "[Designing Machine Learning Systems] 훈련 데이터"
subtitle:   "부제"
categories: study
tags: mlops
comments: true

---

데이터 과학 관점에서 데이터를 처리하는 방법을 살펴본다. ML 모델을 개발하고 개선하는 데 훈련 데이터는 매우 중요하다.

데이터는 지저분하고 복잡하며 예측 불가능하고 잠재적으로 위험하다. 그러므로 데이터 사이언티스트와 ML 엔지니어라면 데이터를 제대로 처리하는 방법을 알아야 한다.

이 장에서는 양질의 훈련 데이터를 얻거나 생성하는 기술을 알아본다. 먼저 훈련 데이터를 선택하는 데 사용하는 다양한 샘플링 기술을 알아본 뒤 레이블 다중성 문제부터 레이블 부족 문제, 클래스 불균형 문제 그리고 데이터 부족 문제를 해결하기 위한 데이터 증강 기술까지 훈련 데이터를 생성할 때 흔히 마주하는 문제를 다룬다.

데이터는 잠재적인 편향으로 가득하다. 편향이 발생하는 원인은 다양하며, 수집, 샘플링, 레이블링 과정에서 발생하기도 한다. 과거 데이터는 사람의 편향을 내포할 수 있고, 해당 데이터로 훈련한 ML 모델은 편향이 더 공고해지도록 할 수 있다. 데이터를 너무 믿지 말자.

(+ '데이터셋'과 '데이터'의 차이, 데이터셋은 유한하고 고정적인 집합을 의미하는 반면 프로덕션 환경의 데이터는 유한하지도 고정적이지도 않다.)

## 4.1 샘플링

다양한 상황에서 샘플링이 필요하지만 이 절에선 주로 훈련 데이터를 생성하기 위한 샘플링 방법에 초점을 둔다.

샘플링은 매우 다양하게 활용되며, 다양한 샘플링 방법을 이해하고 각 방법이 워크플로에서 사용되는 방식을 알면 업무에 큰 도움이 된다. 잠재적인 샘플링 편향을 피할 수 있고, 데이터의 효율성을 향상하는 샘플링 방법을 선택할 수 있다.

샘플링은 크게 비확률 샘플링과 무작위 샘플링으로 나뉜다.

### 4.1.1 비확률 샘플링

비확률 샘플링은 데이터를 확률이 아닌 기준에 의거해 선택하는 방법이다.

- 편의 샘플링(Convenience sampling): 데이터 샘플을 가용성에 의거하여 선택한다.
- 눈덩이 샘플링(Snowball sampling): 기존 샘플을 기반으로 미래의 샘플을 선택한다.
- 판단 샘플링(Judgement sampling): 전문가가 어떤 샘플을 포함할지 결정한다.
- 할당 샘플링(Quota sampling): 무작위화없이 특정 데이터 그룹별 할당량에 의거해 샘플을 선택한다.

확률이 아닌 기준으로 선택한 샘플은 실데이터를 잘 대표하지 못하고 선택 편향이 강하다. 

-> 언어 모델링은 가용성이 높은 위키백과, 커먼 크롤, 레딧 등의 데이터를 주로 활용한다.

-> IMDB 리뷰, 아마존 리뷰는 리뷰를 기꺼이 남기는 사용자 집단에 편향된다.

-> 자율주행차를 훈련을 위한 데이터는 화창한 날씨에 편향되어 있다.

데이터를 선택할 때 활용하기에 알맞지 않으나, 편리하다는 이유로 많이 사용된다. 신뢰성 있는 모델이라면 확률 기반 샘플링을 사용해야 한다.

### 4.1.2 단순 무작위 샘플링

가장 단순한 형태의 무작위 샘플링이라면 모집단의 각 샘플이 선택될 확률이 모두 동일하다. 단순 무작위 샘플링은 구현이 쉽다는 장점이 있다. 반면 드물게 발생하는 범주의 데이터가 포함되지 않을 수 있다는 단점이 있다.

### 4.1.3 계층적 샘플링

계층적 샘플링은 모집단을 상이한 성질의 그룹으로 나눈 뒤 각 그룹에 개별적으로 샘플링을 수행해 단순 무작위 샘플링의 단점을 극복한다. 항상 가능하지는 않으며 모든 샘플을 원하는 그룹으로 나누는 일 자체가 불가능할 때도 있다(**다중 레이블 작업에서 한 샘플이 여러 그룹에 속한다면?**).

### 4.1.4 가중 샘플링

가중 샘플링에서는 각 샘플에 가중치가 있고 이를 기반으로 샘플이 선택될 확률이 결정된다. 이 방법에 도메인 전문 지식을 적용할 수 있다. 데이터의 특정 하위 모집단, 예컨대 최신 데이터가 모델에 더 가치 있고, 따라서 선택 확률을 높이고 싶다면 더 높은 가중치를 부여한다.

보유하고 있는 데이터가 실제 모집단과 다른 분포에서 추출된 경우에도 도움이 된다. A, B 클래스로 이뤄진 데이터 중 실제 모집단은 A, B 비율이 1:1인 반면 보유 데이터의 비율은 3:1이라면, B에 3배 높은 가중치를 부여하고 추출하면 된다.

### 4.1.5 저수지 샘플링

[저수지 샘플링](https://dhpark1212.tistory.com/entry/%EB%B9%84-Reservoir-Sampling)은 프로덕션 환경의 스트리밍 데이터를 처리할 때 특히 유용한 매력적인 알고리즘이다.

지속적으로 수집되는 트윗 스트림이 있고 분석을 하거나 모델을 훈련하기 위해 k개의 트윗을 샘플링한다고 가정했을 때 요구 사항은 다음과 같다.

- 각 트윗이 선택될 확률은 동일해야 한다.
- 알고리즘 가동을 언제든지 멈출 수 있으며 이때 각 트윗이 올바른 확률로 샘플링됐음을 보장해야 한다.

이 문제에 대한 한 가지 솔루션은 저수지 샘플링이다. 알고리즘은 배열 형태로 구현 가능한 저장소를 포함하며 세 단계로 이뤄진다.

1. 첫 $$k$$개의 요소를 저장소에 넣는다.
2. 수집되는 각 $$n$$ 번째 요소마다 $$1 \leq i \leq n$$을 만족하는 난수 $$i$$를 생성한다.
3. $$1 \leq i \leq k$$라면 저장소의 i번째 요소를 $$n$$번째 요소로 교체한다. 아니라면 다음 요소로 넘어간다.

이는 수집되는 각 $$n$$번째 요소가 저장소에 포함될 확률이 $$\frac{k}{n}$$임을 뜻하며, 또한 저장소 내 각 요소가 $$\frac{k}{n}$$의 확률로 선택됨을 증명할 수 있다. 즉 각 샘플이 선택될 확률이 동일하다.

### 4.1.6 중요도 샘플링

중요도 샘플링을 활용하면 원하는 분포가 아닌 다른 확률 분포만 활용 가능한 상황에서도 원하는 확률 분포에서 샘플링을 수행할 수 있다. ML뿐 아니라 다양한 분야에 두루 사용되는 중요한 방법이다.

확률 분포 $$P(x)$$에서 $$x$$를 샘플링해야 하는데 $$P(x)$$는 샘플링 비용이 크고 활용이 어려운 반면 $$Q(x)$$는 샘플링하기가 훨씬 쉽다면?

-> $$Q(x)$$에서 $$x$$를 대신 샘플링하고 해당 샘플의 가중치를 $$\frac{P(x)}{Q(x)}$$로 부여, 이때 $$Q(x)$$는 제안 분포 또는 중요도 분포라 한다.

\* $$E_{P(x)}[x] = \sum_{x}P(x)x = \sum_{x}Q(x)x\frac{P(x)}{Q(x)} = E_{Q(x)}[x\frac{P(x)}{Q(x)}]$$

## 4.2 레이블링

프로덕션 환경 내 ML 모델 대부분은 지도 학습 기반이다. ML 모델 성능은 학습 용도로 레이블을 지정한 데이터의 양과 질에 크게 의존한다.

### 4.2.1 수작업 레이블

데이터에 대해 수작업 레이블을 획득하는 일은 여러 이유로 어렵다. 비용이 크고, 데이터 개인 정보 보호 문제를 야기하고, 느리다.

레이블링이 느리면 작업 반복 속도 또한 느려지고 변화하는 환경과 요구 사항에 대한 모델의 적응성이 떨어지게 된다.

#### 레이블 다중성

기업에서는 레이블이 지정된 데이터를 충분히 얻기 위해 종종 여러 소스에서 온 데이터를 사용하고 전문 지식수준이 상이한 여러 어노테이터에 의존한다.

문제는 어노테이터 간 결과가 불일치하는 상황이 흔히 발생한다는 점이다. 요구되는 도메인 지식수준이 높을수록 서로 불일치할 가능성이 커진다.

어노테이터 간 불일치를 최소화하려면 문제를 명확히 정의해야 한다.

#### 데이터 계보

서로 다른 어노테이터가 생성한 다양한 소스의 데이터를 품질에 대한 고민 없이 무분별하게 사용하면 모델에 알 수 없는 문제가 발생할 수 있다.

**"데이터 샘플 10만개로 학습한 모델의 성능이 적당히 좋았다. 그래서 큰 비용을 들여 데이터 샘플 100만개를 추가로 확보하고 모델을 학습했더니 오히려 성능이 떨어졌다. 설상가상으로 기존 샘플과 새로운 샘플이 섞여서 문제를 해결하기 더욱 까다로워졌다."**

위와 같은 상황을 미연에 방지하려면 각 데이터 샘플과 레이블의 출처를 추적 가능하게 설정해두는 편이 좋다. 이러한 세부 구현을 **데이터 계보(data lineage)** 기법이라고 한다.

### 4.2.2 자연 레이블

자연적인 그라운드 트루스 레이블이 존재하는 작업에서도 존재한다. 자연적으로 얻은 그라운드 트루스 레이블을 자연 레이블이라고 칭하며, 자연 레이블이 있는 경우 모델 예측을 자동으로 평가하거나 시스템상에서 부분적으로 평가할 수 있다.

구글 지도에서 특정 경로의 도착 시간 예측, 주가 예측, 사용자가 추천받은 항목에 대한 실제 클릭 여부 등 자연 레이블을 얻을 수 있는 경우는 많이 존재한다.

작업에 자연 레이블이 없더라도 모델에 대한 피드백을 수집하게끔 시스템을 설정하는 방법이 있다. 구글 번역의 경우 번역이 적절하지 않은 경우 사용자 커뮤니티에서 다른 번역을 제출할 수 있도록 옵션을 마련해둔다(제안된 번역 품질이 괜찮은지는 확인해야한다).

추천 시스템 사례에서 사용자가 제안된 추천에 대해 일정 시간이 지나도 클릭하지 않는 경우 추천은 좋지 못한 것으로 간주한다. 이러한 음성 레이블은 양성 레이블의 부재를 통해 추정하므로 **암시적 레이블**이라고 한다. 사용자가 추천 항목에 낮은 평점을 부여하거나 거부를 표해서 명시적으로 피드백을 주는 **명시적 레이블**과는 반대이다.

#### 피드백 루프 길이

자연 레이블이 존재하는 작업에서 예측을 수행한 시점부터 피드백을 얻는 시점까지 걸리는 시간을 피드백 루프 길이라고 한다.

피드백을 포착할 윈도 길이(window length)를 적절히 결정하려면 깊은 고민이 필요하다. 속도와 정확도 사이 트레이드오프가 있기 때문이다. 

윈도 길이가 짧으면? -> 레이블을 더 빨리 얻고 레이블을 이용해 모델의 문제를 조기에 발견하고 빠르게 해결 가능하나 너무 이른 시점에 판단하여 레이블을 잘못 지정할 수 있다.

윈도 길이가 길면? -> 자연 레이블을 몇 주 또는 몇 달 동안 얻지 못하기도 한다(ex. 이상 거래 탐지). 분기별 혹은 연간 비즈니스 보고서를 통해 모델 성능을 보고하는데 도움이 되나 모델 결함을 빠르게 발견해야 한다면 문제가 된다.

### 4.2.3 레이블 부족 문제 해결하기

고품질 레이블을 충분히 얻기란 어려운 일이며, 이를 해결하기 위해 많은 기술이 개발되었다.

#### 약한 지도 학습(Weak supervision)

약한 지도 학습의 기반이 되는 인사이트는 데이터를 레이블링할 때 도메인 전문 지식을 통해 개발된 휴리스틱을 활용한다는 점이다.

예를 들어, 의사가 *간호사 노트에 폐렴 같은 심각한 상태가 언급되면 해당 환자를 우선적으로 고려해야 한다*는 휴리스틱을 활용한다고 하면,

```
def labeling_func(note):
    if "페렴" in note:
        return "위급"
```

위와 같이 휴리스틱을 인코딩한 레이블링 함수(LF)를 레이블링하려는 샘플에 적용한다.

LF로 다양한 유형의 휴리스틱을 인코딩할 수 있다.

- 키워드 휴리스틱: 특정 키워드가 존재하는 경우

- 정규 표현식: 특정 정규 표현식과 일치하거나 일치하지 않는 경우

- 데이터베이스 조회: 위험 질병 목록에 등재된 질병 이름이 포함된 경우

- 다른 모델의 출력: 기존 시스템이 환자를 위급으로 분류하는 경우

이론적으로 수작업이 필요없지만 LF가 얼마나 정확한지 확인하기 위해 약간의 수작업 레이블을 이용하는 것이 좋다.

약한 지도 학습은 데이터에 개인 정보 보호 요구 사항이 엄격하게 적용될 때 특히 유용하다.

LF를 사용하면 도메인 전문 지식에 버전을 지정하고 그것을 재사용하거나 공유할 수 있다.

종종 휴리스틱으로 레이블링을 잘 할 수 있는데 왜 ML 모델이 따로 필요하냐고 묻는다면 LF가 데이터 샘플 전체를 다루지 못할 수 있기 때문이라고 한다.

약한 지도 학습은 간단하지만 강력하다. 하지만 실제로 사용했을때 잡음이 많을 수 있는 등 완벽하지 않다.

#### 준지도 학습(Semi-supervision)

준지도 학습은 구조적인 가정을 활용해 초기에 수집한 소수의 레이블을 기반으로 새로운 레이블을 생성한다. 따라서 초기에 수집한 레이블이 필요하다.

대표적인 준지도 학습 방법으로 **자가 훈련**이 있다. 먼저 레이블이 지정된 기존 데이터로 모델 학습을 시작한 뒤 해당 모델로 레이블이 미지정된 샘플에 예측을 수행한다. 어떤 샘플의 원시 확률 점수가 높다면 예측이 정확하다고 가정하고 예측된 레이블로 레이블링한 뒤 훈련 세트에 추가한다.

또 다른 방법으로는 유사한 특성이 있는 데이터 샘플끼리는 레이블이 동일하다고 가정하는 것이다. 트위터 해시태그 주제 분류 작업에서 해시태그 사이의 유사성을 사용하는 것이 좋은 예이다. 대부분의 경우 클러스터링 알고리즘을 사용하는 등 더 복잡한 방법을 적용한다.

준지도 학습은 훈련할 레이블의 개수가 제한적일 때 가장 유용하다(?).

#### 전이 학습(Transfer learning)

전이 학습은 특정 작업을 위해 개발한 모델을 시작점으로 삼아 후속 작업에 재사용하는 일련의 방법론이다. 대표적인 예시는 언어 모델링이다. Next Token Prediction 방식으로 사전 학습한 언어 모델을 다운스트림 테스크에서 활용한다.

전이 학습은 레이블링된 데이터가 많지 않은 작업에 특히 적합하다. 레이블링된 데이터가 많더라도 사전 훈련한 모델을 사용하면 성능이 더욱 향상된다.

#### 능동적 학습(Active Learning)

능동적 학습은 데이터 레이블링 작업의 효율성을 향상한다. ML 모델 학습할 데이터를 선택하는 것으로, 능동적 학습자인 모델이 레이블링되지 않은 샘플에 대해 질의하면 어노테이터가 그것에 레이블을 지정한다. 

레이블을 무작위로 골라 지정하기보단 특정 지표나 휴리스틱에 근거해 모델에가 가장 필요한 샘플을 선택해 레이블링한다. 예를 들어 모델이 여러 클래스의 원시 확률을 출력하는 분류 문제에서 예측한 원시 확률의 엔트로피가 가장 높은(모델이 헷갈려하는) 샘플을 선택해 레이블링한다.

또 다른 방법으로, 다양한 후보 모델 간의 불일치를 기반으로 하는 휴리스틱도 일반적으로 사용한다. 이 방법을 위원회에 대한 질의(query-by-committee)라고 하며 앙상블 방법의 예로 볼 수 있다.

레이블링할 샘플은 다양한 데이터 구도에서 수집된다. 프로덕션 환경처럼 데이터 스트림의 원천인 실제 세계 확률 분포가 존재할 때 모델을 흘러들어오는 데이터 스트림에서 레이블링할 샘플을 선택하기도 한다.

## 4.3 클래스 불균형 문제

클래스 불균형이란 일반적으로 분류 작업에서 나타나는 문제로, 훈련 데이터 내 클래스당 샘플 개수가 크게 차이 나는 문제를 의미한다.

클래스 불균형은 레이블이 연속 값인 회귀 문제에서도 발생한다. 예를 들어, 의료비 청구액을 추정할 때 청구액은 분포가 크게 치우쳐 있다.

### 4.3.1 클래스 불균형 문제의 어려움

1. 모델이 소수 클래스를 찾아내는 법을 학습하기에 신호가 충분하지 않다.

2. 모델이 데이터에 내재하는 유용한 패턴을 학습하는 대신 단순 휴리스틱을 활용하려는 경향이 강해지고, 최적이 아닌 해를 고집하게 된다.

3. 클래스 불균형은 주로 비대칭적인 오차 비용 문제로 이어진다(폐암 탐지 사례에서 암세포가 있는 엑스레이 이미지를 오분류한다면?).

현실에서는 드물게 발생하는 사건이 일반적인 사건보다 훨씬 흥미롭고 결과 또한 더 중요하다. 대다수의 작업에서 이렇게 드물게 발생하는 사건을 탐지하는 일이 주목적이다(이상 거래 탐지, 질병 스크리닝, 이력서 스크리닝, ...).

샘플링 프로세스에서 발생한 편향으로 클래스 불균형이 야기될 때도 있다.

레이블링 오류 또한 클래스 불균형을 야기할 수 있다.

데이터를 조사해가며 클래스 불균형의 원인을 이해하는 과정도 중요하다.

### 4.3.2 클래스 불균형 처리하기

불균형에 대한 민감도가 문제의 복잡도에 따라 증가하며, 복잡도가 낮고 선형으로 분리 가능한 문제는 클래스 불균형 정도에 상관없이 영향받지 않는다.

신경망의 학습 능력이 향상됨에 따라 어떤 이들은 클래스 불균형을 일부러 '수정'해서는 안 된다고 주장한다. 그 불균형이 데이터가 실제로 나타나는 모습이라면 말이다.

#### 올바른 평가 지표 사용하기

클래스 불균형이 있는 작업을 다룰 때는 적절한 평가 지표를 선택하는 일이 중요하다.

전체 정확도는 ML 모델의 성능을 보고할 때 자주 사용되지만 데이터 불균형이 있는 경우 적합하지 않다.

정확도를 각 클래스에 개별적으로 활용한다면 괜찮은 지표로 사용할 수 있다.

정밀도, 재현율, F1은 좋은 평가 지표가 될 수 있다. 어떤 클래스를 양성 클래스로 간주할지에 따라 값이 바뀌는 비대칭 지표이므로 목적에 따라 양성 클래스를 무엇으로 할지 판단해야한다.

분류 임계값을 조정해 분류 목적에 맞는 분류기를 선택할 수 있다. ROC 곡선 혹은 정밀도-재현율 곡선을 참고하면 좋고, 양성 클래스에 초점을 맞추고 있으므로 이 부분을 유의해야한다.

ROC 곡선: 실제 음성인 것 중 양성이라고 잘못 예측한 경우가 적고(오경보율이 낮다), 실제 양성인 것 중 대부분 양성이라고 예측함(재현율이 높다)

정밀도-재현율 곡선: 양성으로 예측한 것은 실제 양성인 경우가 많고(정밀도가 높다), 실제 양성인 것 중 대부분 양성이라고 예측함(재현율이 높다)

#### 데이터 수준의 방법: 리샘플링

훈련 데이터의 분포를 수정해 불균형 정도를 줄여서 모델 학습을 더 용이하게 만드는 방법이다.

다수의 클래스에서 데이터 포인트를 제거하는 언더샘플링 방식과 소수의 클래스에서 데이터 포인트를 늘리는 오버샘플링 방식이 있다.

간단한 언더샘플링 방식으로 토멕 링크가 있고, 오버샘플링 방식으로 SMOTE가 인기 있다. 두 방식 모두 저차원 데이터에서만 효과적이다.

니어-미스나 단측 선택같이 정교한 리샘플링 기법은 대부분 데이터 포인트 사이 혹은 데이터 포인트와 결정 경계 사이의 거리를 계산해야 하므로 고차원 데이터 또는 고차원 피처 공간에서 비용이 너무 크거나 실행이 불가능하다.

훈련 데이터를 리샘플링한다면 리샘플링된 데이터에서 모델을 평가하지 말아야 한다.

2단계 학습법도 있다. 먼저 각 클래스에 데이터 포인트가 $$N$$개만 남을 때까지 다수 클래스를 무작위로 언더샘플링한 데이터로 모델을 학습한 후, 원래 데이터로 모델을 미세 조정한다.

동적 샘플링이라는 방법도 있다. 학습 과정에서 성능이 낮은 클래스를 오버샘플링하고 성능이 높은 클래스를 언더샘플링한다.

#### 알고리즘 수준의 방법

학습 데이터 분포를 그대로 유지하면서 클래스 불균형에 더 강건한 알고리즘으로 변경하는 방법이다. 대부분 손실 함수를 조정한다.

특정 데이터 포인트의 손실이 크다면 모델은 해당 데이터 포인트를 올바르게 예측하는 일을 우선시해야 한다. 우선시 할 데이터 포인트에 가중치를 주는 방식으로 접근한다.

##### 비용 민감 함수

클래스마다 오분류 비용이 다르다는 통찰을 기반한다. 클래스 별 서로 다른 비용을 고려해 각 손실 값을 수정한 방식이다.

클래스 별 가중치를 수작업으로 정의해야 한다는 문제점이 있다.

##### 클래스 균형 손실

불균형 데이터셋으로 훈련한 모델에서는 다수 클래스로 편향되고 소수 클래스에서 예측을 잘 못하는 현상이 일어나므로 전체 샘플의 개수 중 클래스 별 비중에 따라 가중치를 부여하는 방식이다. 기본적으로는 각 클래스의 가중치를 해당 클래스의 샘플 수에 반비례하기 만든다.

##### 초점 손실(Focal loss)

모델이 분류하기 어려운 샘플을 집중적으로 학습하도록 인센티브를 준다. 예측이 맞을 확률이 낮을수록 샘플 가중치가 커지도록 손실을 조정한다.

## 4.4 데이터 증강

데이터 증강은 훈련 데이터 양을 늘리는 데 사용하는 기법이다. 증강 데이터는 모델이 잡음과 적대적 공격에 더 강건해지도록 한다.

### 4.4.1 단순 레이블 보존 변환

컴퓨터 비전과 자연어 처리에서 모두 사용되는 간단한 방법이다.

컴퓨터 비전에서는 레이블은 그대로 두고 이미지를 자르고, 뒤집고, 회전하는 등의 처리를 주어 기존 이미지만 수정하는 식으로 데이터를 늘린다.

자연어 처리에서는 유의어를 활용하거나 단어 임베딩 공간에서 임베딩이 유사한 단어로 일부 단어를 대체하는 방식으로 데이터를 늘린다.

이러한 데이터 증강 유형은 훈련 데이터를 두세 배로 손쉽게 늘리는 방법이다.

### 4.4.2 교란

속임수가 있는 데이터를 사용해 신경망이 잘못된 예측을 하도록 속이는 것을 적대적 공격이라고 하며, 샘플에 잡음을 추가하는 것은 적대적 샘플을 생성하는 일반적인 기법이다. 신경망은 이러한 잡음에 민감하며 컴퓨터 비전에서는 이미지에 잡음을 소량만 추가해도 신경망이 이미지를 잘못 분류할 수 있는 것으로 알려져 있다.

훈련 데이터에 잡음 샘플을 추가하면 모델이 학습한 결정 경계에서 약점을 인식하고 성능을 개선하는 데 도움이 된다.

자연어 처리에서는 일반적으로 잘 쓰이지 않는다. 임의의 문장에 임의의 문자를 추가하면 헛소리처럼 보일 가능성이 높기 때문이다. BERT의 사전 학습 과정에서 마스킹된 토큰 중 10%를 골라 임의의 단어로 대체하는데 자연어 처리에서 교란이 사용된 예시로 볼 수 있다.

### 4.4.3 데이터 합성

합성 데이터로 모델을 훈련하고자 하는 시도이다.

자연어 처리에서 템플릿을 사용해 낮은 비용으로 모델을 부트스트랩할 수 있다. 가령 대화형 챗봇을 위한 훈련 데이터를 합성하고자 한다면 **[위치]에서 [숫자]마일 이내에 있는 [세계] 음식점을 찾아주세요.** 라는 템플릿을 활용해 훈련용 질의문 수천 개를 생성한다.

컴퓨터 비전에서는 이산 값의 레이블을 갖는 기존 데이터 포인트를 결합해 연속 값의 레이블을 생성하는 믹스업 방법이 있다. 개(1)와 고양이(2)라는 두 가지 레이블로 이미지를 분류하는 작업을 가정하면,

$$x^{'} = \gamma x_1 + (1 - \gamma) \times x_2$$

위와 같이 개 레이블의 데이터 포인트 $$x_1$$과 고양이 레이블의 데이터 포인트 $$x_2$$의 조합으로 $$x^{'}$$를 합성한다.

신경망으로 훈련 데이터를 합성하는 작업은 활발히 연구되고 있다.

## 4.5 정리

알고리즘이 의미 있는 것을 학습하도록 훈련 데이터를 선별하고 생성하는 데 시간과 노력을 투자해야 한다.

훈련 데이터를 생성하는 여러 단계를 논의했다.

문제에 적절한 데이터를 샘플링하는 데 도움이 되는 비확률 샘플링과 무작위 샘플링 등을 다뤘다.

레이블 수집과 관련된 내용을 다뤘다. 자연 레이블, 자연 레이블이 없는 경우 수작업 레이블, 수작업 레이블 부족으로 인한 해결 방안 등을 확인했다.

데이터 분포가 불균형한 경우 ML 알고리즘 학습이 어려운 이유를 논의했다. 이어서 올바른 지표를 선택하는 법, 데이터 리샘플링, 특정 샘플에 집중하도록 손실 함수를 수정하는 법까지 다뤘다.

마지막으로 컴퓨터 비전과 자연어 처리에서 데이터 증강 기법은 무엇이 있는지 확인했다.

