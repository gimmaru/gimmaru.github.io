---
layout: post
title:  "[Designing Machine Learning Systems] 피처 엔지니어링"
subtitle:   "부제"
categories: study
tags: mlops
comments: true

---

⌜[Practical lessons from predicting clicks on ads at facebook](https://dl.acm.org/doi/abs/10.1145/2648584.2648589)⌟에서는 올바른 피처를 보유하는 것이 ML 모델을 개발하는 데 가장 중요하다고 말한다. 책의 필자도 협업했던 많은 회사에서 실행 가능한 모델이 있는 한 올바른 피처를 보유하는 것이 하이퍼파라미터 조정 같은 알고리즘 기법보다 큰 성능 향상을 이끌어내는 경우가 많다고 한다.

ML 엔지니어링과 데이터 과학에서는 유용한 신규 피처를 생성하는 일이 상당한 부분을 차지한다.

피처 엔지니어링 관련 기법과 중요한 고려 사항을 살펴보고, ML 프로덕션에서 많은 문제를 일으키는 데이터 누수(data leakage)를 감지하고 방지하는 법을 살펴본다.

마지막으로는 피처 중요도와 피처 일반화를 함께 고려해 좋은 피처를 설계하는 방법을 논의한다.

## 5.1 학습된 피처 vs. 엔지니어링된 피처

딥러닝의 장점은 수작업으로 피처를 만들 필요가 없다는 것, 그렇다면 왜 피처 엔지니어링이 중요한가?

많은 피처들이 알고리즘에 의해 자동으로 학습되고 추출된다. 다만 모든 피처를 자동화하려면 아직 멀었다.

가령 텍스트나 이미지 데이터는 딥러닝 모델이 유용한 피처를 추출하는 것을 학습한다. 과거 텍스트를 전처리하는 과정에서 필요했던(표제어 추출, 줄임말 확장, 구두점 제거, ...) 작업들을 수행하는 대신 문장을 토큰화하고, 토큰화된 문장을 딥러닝 모델에 전달하면 문장과 토큰으로부터 유용한 피처를 추출하는 것을 학습한다. 이미지에서도 비슷한다. 원시 이미지에서 수동으로 피처를 추출해 ML 모델에 입력하는 대신 원시 이미지를 딥러닝 모델에 직접 입력할 수 있다.

한편 ML 시스템에 텍스트와 이미지 외의 데이터가 필요한 경우가 있다. 예를 들어, 댓글의 스팸 여부를 감지할 때는 댓글 텍스트 외에 다음과 같은 정보를 사용한다.

- **댓글**, 찬성과 반대가 몇개인가?
- **댓글을 게시한 사용자**, 계정이 언제 생성됐고, 얼마나 자주 게시하며, 찬성과 반대를 얼마나 많이 얻었는가?
- **댓글이 게시된 스레드**, 조회 수가 몇인가? 인기 있는 스레드일수록 스팸성 댓글이 많은 경향이 있다. 

피처 엔지니얼이은 사용할 정보를 선택하고 이 정보를 ML 모델에서 사용하는 포맷으로 추출하는 프로세스이다.

## 5.2 피처 엔지니어링 기법

데이터의 피처를 전처리할 때 고려할 중요한 작업 몇 가지를 알아본다.

### 5.2.1 결측값 처리

결측값에는 세 가지 유형이 있다.

- **비무작위 결측(MNAR, Missing not at random)**: 결측값이 발생한 이유가 실제 값 자체에 있다.
- **무작위 결측(MAR, Missing at random)**: 결측값이 발생한 이유가 값 자체가 아닌 다른 관측 변수에 있다.
- **완전 무작위 결측(MCAR, Missing completely at random)**: 결측값에 패턴이 없다.

결측값은 특정 값으로 채우거나(대치) 제거(삭제)해 처리한다.

#### 결측값 삭제(Deletion)

삭제가 대치보다 쉽기 때문에 삭제를 더 선호하는 경향이 있다.

**열 삭제**: 누락된 값이 너무 많다면 변수 자체를 삭제한다.

**행 삭제**: 누락된 값이 있는 샘플을 제거한다. 결측값이 완전 무작위이며 결측값이 있는 샘플의 비중이 적을 때(ex. 0.1% 미만) 유용하다.

손쉽지만 중요한 정보가 손실되고 모델에 편향이 발생할 수 있다는 단점이 있다.

#### 결측값 대치(Imputation)

특정 값으로 결측값을 대치한다. '특정 값'을 결정하는 일은 어렵다.

일반적으로 기본 값으로 채운다. 예를 들어, 작업이 누락된 경우 빈 문자열("")로 채우거나 평균, 중앙값 또는 최빈값으로 채운다.

데이터에 자신의 편향을 주입하고 데이터에 잡음을 더할 수 있으며 더 심하게는 데이터 누수의 위험이 있다.

<br/>

결측값 삭제와 대치 모두 대체로 잘 작동하지만 때로 문제가 될 수 있다.

일반적으로 결측값을 가능한 값으로 채우지 않는 편이 좋다. 예를 들어, 자녀 수 피처의 결측값은 0으로 채우지 않는게 좋은데, 결측값을 0으로 채우면 정보가 없는 사람과 자녀가 없는 사람을 구분하기 어렵기 때문이다.

### 5.2.2 스케일링

모델에 피처를 입력하기 전에 각 피처를 유사한 범위로 스케일링하는 것은 중요하다. 몇몇 ML 모델들(그래디언트 부스트 트리, 로지스틱 회귀, ...)은 피처의 스케일에 따라 피처 별 중요도를 달리 인식하기도 하기 때문이다.

직관적인 스케일링 방식으로는 Min-Max 스케일링이 있다. 기본적으로 [0, 1] 범위로 피처의 스케일을 조정해준다. 필자는 [-1, 1] 범위러 스케일을 조정했을 때 경험상 더 잘 동작한다고 한다.

변수가 정규 분포를 따른다고 생각된다면 평균과 단위 분산이 0이 되도록 정규화하면 도움이 된다. 이를 표준화(standardization)이라고 한다.

ML 모델은 비대칭 분포를 따르는 피처로 어려움을 겪는 경향이 있다. 왜곡을 완화하는 기법으로는 일반적으로 피처에 로그 변환을 적용한다. 성능이 향상될 때가 많지만 모든 경우에 작동하지는 않는다.

스케일링에 관한 주의 사항이 두 가지 있다. 1) 스케일링은 흔히 데이터 누수의 원인이 된다. 2) 전역 통계치가 필요한 경우가 많다. 그렇기 때문에 데이터 누수가 발생하지는 않는지 확인하고, 모델을 자주 재훈련해야 한다.

### 5.2.3 이산화

이산화는 연속형 피처를 불연속형 피처로 바꾸는 과정이다. 양자화 또는 비닝이라고도 한다.

이산화를 적용하면 모델은 무한한 번주에 대해 훈련할 필요 없이 훈련하기 쉬운 특정 범주로 훈련하는데 집중할 수 있다. 훈련 데이터가 제한된 경우 더 유용하다.

단점은 범주 경계에서 불연속성을 발생시킨다는 점이다. 범주의 경계를 선택하기도 쉽지 않다.

### 5.2.4 범주형 피처 인코딩

범주가 '정적'이라고 가정하는 경향이 많지만 프로덕션 환경에서는 범주가 변화한다. 신규 제품 브랜드, 신규 계정, 신규 제품 유형, 신규 웹사이트 도메인, 신규 음식점, 신규 회사, 신규 IP 주소 등 범주형 피처 중 훈련 데이터에서 다루지 못한 새로운 범주가 추가되면, 그 범주를 처리하기 위해 해결 방안을 찾아야 한다.

한 가지 해결책은 마이크로소프트에서 개발한 Vowpal Wabbit 패키지에 의해 대중화된 **해싱 트릭**이다. 트릭의 요지는 해시 함수를 각 범주의 해시 값을 생성하는 것이다. 해시된 값은 해당 범주의 인덱스가 된다. 해시 공간을 지정할 수 있으므로 범주가 몇 개인지 알 필요 없이, 피처에 대해 인코딩된 값의 개수를 미리 고정할 수 있다.

해시 함수의 한 가지 문제는 충돌이다. 두 범주에 동일한 인덱스가 할당되는 상황이다. 다행히 해시 피처가 충돌해도 영향이 그리 크지 않은 것으로 알려져 있다.

### 5.2.5 피처 교차

피처 교차는 둘 이상의 피처를 결합해 새로운 피처를 생성하는 기법으로, 피처 간의 비선형 관계를 모델링하는 데 유용하다.

선형 회귀, 로지스틱 회귀와 같이 비선형 관계를 학습할 수 없는 모델에 필수이며 신경망에는 비교적 덜 중요하지만 여전히 유용하다. 명시적 피처 교차가 신경망에서 비선형 관계를 더 빠르게 학습하는 데 도움이 되기 때문이다.

피처 교차 기법을 사용할 때 유의할 점은 피처 공간이 폭발할 수 있다는 점이다.

### 5.2.6 이산 및 연속 위치 임베딩

위치 임베딩은 ⌜[Attention is all you need](https://arxiv.org/abs/1706.03762)⌟를 통해 딥러닝 커뮤니티에 처음 소개된 후 컴퓨터 비전과 NLP 분야의 많은 애플리케이션에서 표준 데이터 엔지니어링 기술로 자리 잡았다.

언어 모델링을 떠올려 볼 때, 순환 신경망을 활용하면 단어가 순차적으로 처리되지만, 프랜스포머 같은 모델을 사용하면 단어가 병렬로 처리되므로 모델이 순서를 알 수 있도록 단어 위치를 명시적으로 입력해야 한다. 이 때 모델에 절대 위치(0, 1, 2, ...)을 입력값으로 사용하지는 않는데, 경험적으로 신경망은 단위 분산을 갖고 있지 않은 입력값에는 잘 작동하지 않기 때문이다. 그렇다고 위치를 0과 1 사이로 리스케일링한다고 하면 위치 간 차이가 너무 작아 신경망이 이를 구별하는 법을 학습하기 어려워진다.

위치 임베딩을 적용하기 위해 단어 임베딩처럼 위치 임베딩을 처리하고, 단어 임베딩에 더해주는 식으로 위치 정보를 전달한다.

## 5.3 데이터 누수

`테스트했을 땐 잘 동작했는데, 프로덕션 환경에서 써보니 잘 동작하지 않는다.. 원인이 무엇일까?`

데이터 누수는 훈련 데이터셋의 피처 집합으로 레이블 정보가 누수되는 현상을 의미하는데, 추론 시에 사용하는 입력 데이터에는 그 정보가 존재하지 않는 경우이다.

### 5.3.1 일반적인 원인

#### 시간 대신 무작위로 시간적 상관 데이터를 분할한 경우

미래 정보가 훈련 과정에 유출돼 모델이 평가 중 부정행위를 하는 것을 방지하려면 가능한 한 데이터를 무작위로 분할하는 대신 시간별로 분할해야 한다.

#### 분할 전 스케일링을 수행한 경우

항상 스케일링 전에 먼저 데이터를 분할하고 훈련 분할의 통계치를 사용해 모든 분할을 스케일링해야 한다.

#### 테스트 분할의 통계치로 결측값을 채운 경우

스케일링으로 인한 누수와 유사하며, 방지하려면 모든 분할의 결측값을 채울 때 훈련 분할의 통계치만 사용해야 한다.

#### 분할 전 데이터 중복을 제대로 처리하지 않은 경우

이러한 경우 동일한 샘플이 훈련, 검증, 테스트 분할 모두에 나타날 수 있다.

분할 전과 분할 후 데이터 중복 여부를 항상 확인해야 한다. (+ 데이터를 오버샘플링하려면 분할 전이 아니라 분할 후에 수행해야 한다.)

#### 그룹 누수

강한 레이블 상관관계를 갖는 데이터 포인트들(그룹)이 다른 분할로 나뉘어 들어가는 경우

데이터가 어떻게 생성됐는지 이해해야 하지 않고는 피하기 어렵다.

#### 데이터 생성 과정에서 누수가 생긴 경우

암 징후를 예측하기 위해 A 병원과 B 병원에서 이미지 데이터를 수집했다.

이 후에 검증 과정에서 확인해보니 A 병원과 B 병원의 CT 촬영 기기가 달랐고, 이미지의 해상도에서 차이를 보였다.

이러한 차이에 레이블과 관련된 정보가 담겨 있다면 문제가 된다.

이러한 경우 그룹 누수 사례와 마찬가지로 데이터가 어떻게 생성됐는지 이해해야 한다.

### 5.3.2 데이터 누수 검출

데이터 누수는 ML 프로젝트의 여러 단계에서 발생하므로 이를 모니터링하는 것은 중요하다.

레이블(타깃 변수)에 대한 각 피처 또는 피처 집합의 예측 검정력을 측정한다. 피처의 상관관계가 비정산적으로 높다면 해당 피처가 생성되는 방식과 상관관계가 적절한지 조사한다.

피처 또는 피처 집합이 모델에 얼마나 중요한지 측정하려면 절제 연구를 수행하라. 피처 제거 시 모델 성능이 크게 저하된다면 해당 피처가 왜 중요한지 조사한다.

모델에 새로 추가된 피처를 주시하라. 신규 피처가 추가됐을 때 모델 성능이 크게 향상되었다면 레이블에 대한 정보가 유출되지는 않았는지 의심해봐야 한다.

테스트 분할을 함부로 사용해서는 안 된다.

## 5.4 좋은 피처를 설계하는 방법

피처가 모델에 적합한지 평가할 때는 모델에 대한 중요도(피처 중요도)와 본 적 없는 데이터에 대한 일반화를 고려해야 한다.

### 5.4.1 피처 중요도

피처 중요도를 측정하는 방식은 여러 가지다. ML 알고리즘이 구현된 패키지에 구현된 내장 피처 중요도 함수를 사용하는 방법도 있고, [SHAP(SHapley Additive exPlanations)](https://github.com/shap/shap/tree/master)도 좋은 방법이다. [InterpertML](https://github.com/interpretml/interpret)이라는 오픈 소스 패키지는 피처 중요도를 활용해 모델의 예측 방식을 이해하는 데 도움이 된다.

피처 중요도 기법은 올바른 피처를 선택하는 데 유용할 뿐 아니라 모델이 내부에서 작동하는 방식을 이해하는 데 도움이 되므로 해석 가능성에도 좋다.

### 5.4.2 피처 일반화

본 적 없는 데이터에 대해 정확한 예측을 하는 것이 ML 모델의 목표이므로 모델에 사용된 피처는 본 적 없는 데이터로 일반화돼야 한다.

피처 일반화 측정은 피처 중요도 측정보다 훨씬 덜 과학적이며, 통계 지식 외에 직관과 주제 전문 지식 모두 필요하다. 일반화와 관련해, 전반적으로 피처 커버리지와 피처 값 분포를 고려해보아야 한다.

피처 커버리지는 데이터에서 해당 피처에 대한 값이 있는 샘플의 백분율이다. 결측값이 높다면 커버리지는 낮다. 커버리지가 낮은 피처는 별로 유용하지 않다. 다만 결측값이 무작위가 아닌 경우에는 유용할 수 있다.

훈련 데이터의 피처 값 분포와 본 적 없는 데이터에 나타나는 피처 값 분포와 겹치지 않으면 모델 성능에 해가 된다. 피처 값 분포가 같은지 확인하는 것이 필요하다.

## 5.5 정리

ML 시스템의 성공은 피처에 달려 있다. 프로덕션 환경에서 ML을 사용할 때 피처 엔지니어링에 시간과 노력을 투자해야 한다.

좋은 피처를 설계하는 방법은 복잡한 문제이며 정답이 없다. 가장 좋은 학습법은 경험을 통해 배우는 것이다.

앞서 다룬 피처 엔지니어링에 대한 모범 사례를 요약하면 다음과 같다.

- 데이터는 무작위로 분할하는 대신 시간별로 학습, 검증, 테스트 분할로 분할한다.
- 데이터 오버샘플링은 분할 후에 수행한다.
- 데이터 누수를 방지하기 위해 스케일링과 정규화는 데이터 분할 후에 수행한다.
- 피처를 스케일링하고 결측값을 처리할 때는 전체 데이터 대신 훈련 분할의 통계치만 사용한다.
- 데이터 생성, 수집, 처리 방식을 이해해야 한다. 가능하면 도메인 전문가를 참여시켜라.
- 데이터 계보를 추적한다.
- 모델에 대한 피처 중요도를 이해한다.
- 잘 일반화되는 피처를 사용한다.
- 모델에서 더 이상 유용하지 않은 피처를 제거한다.