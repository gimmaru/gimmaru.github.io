---
layout: post
title:  "[Designing Machine Learning Systems] 모델 배포와 예측 서비스"
subtitle:   "부제"
categories: study
tags: mlops
comments: true

---

반복 프로세스의 또 다른 부분인 모델 배포를 알아본다. 배포는 일반적으로 '모델을 실행하고 액세스 가능하게 함'을 의미하는 포괄적인 용어이다.

프로덕션의 스펙트럼은 다양하다. 어떤 경우에는 멋진 플롯을 작성하는 일을 의미하고, 또 어떤 경우에는 하루 수백만 명 사용자를 위해 모델을 계속 가동하는 것을 의미한다.

첫 번째 경우 개발 환경과 프로덕션 환경이 유사하지만, 두 번째 경우 그렇지 않고 이 장의 내용이 도움이 될 것이다.

"어려운 부분을 모두 무시하면 배포가 쉽다." 하지만 사용자 수백만 명이 모델을 밀리초 단위 레이턴시와 99% 가동 시간으로 사용하도록 하고, 문제 발생 시 적절한 사람에게 즉시 알리도록 인프라를 설정하고, 잘못된 부분을 파악하고 문제를 수정하기 위해 업데이트를 원활하게 배포하는 것은 어렵다.

ML 모델 배포와 관련이 있든 없든, 모델이 사용되는 방식을 이해함으로써 모델의 제약 조건을 이해하고 목적에 맞게 조정하는 데 도움이 된다.

첫 번째 절에서는 ML 배포에 대한 몇 가지 통념을 짚어본다.

모델이 예측을 생성하고 사용자에게 제공하는 주요 방법인 온라인 예측과 배치 예측을 알아본다.

예측 생성을 위한 계산이 수행되는 곳, 즉 디바이스(에지라고도 함) 상 모델 배포와 클라우드상 모델 배포를 알아본다.

## 7.1 머신러닝 배포에 대한 통념

모델 배포 경험이 없는 사람들은 프로세스를 두려워하거나, 반대로 소요되는 시간과 노력을 과소평가한다.

### 7.1.1 통념 1: 한 번에 한두 가지 머신러닝 모델만 배포한다.

실제 애플리케이션에는 다양한 기능이 있고 각 기능에는 자체 모델이 필요하다.

<p><img src="{{ site.baseurl }}/assets/img/2024-01-03-study-mlops-designing_ml_systems_7-netflix_various_task.png" alt="넷플릭스에서 ML을 활용하는 여러 작업"></p>

위 이미지는 넷플릭스에서 ML을 활용하는 여러 작업을 보여준다.

### 7.1.2 통념 2: 아무것도 하지 않으면 모델 성능은 변하지 않는다.

시간에 따라 소프트웨어 프로그램이 아무런 변화가 없어 보임에도 성능이 저하되는 현산을 소프트웨어 부패 또는 비트 부패라고 한다.

게다가 ML 시스템은 프로덕션에서 모델이 접하는 데이터 분포가 훈련된 데이터 분포와 다를 때 데이터 분포 시프트 문제를 겪는다.

### 7.1.3 통념 3: 모델을 자주 업데이트할 필요 없다.

모델 성능은 시간에 따라 저하되므로 최대한 빨리 업데이트해야 한다.

웨이보는 일부 ML 모델을 10분마다 업데이트한다.

### 7.1.4 통념 4: 대부분의 머신러닝 엔지니어는 스케일에 신경 쓰지 않아도 된다.

'스케일'이 의미하는 바는 애플리케이션마다 다르지만, 예로는 초당 수백 개의 쿼리를 처리하거나 한 달에 수백만 명의 사용자를 처리하는 시스템이 있다.

ML 관련 직업을 구하고 있다면 직원 100명 이상인 회사에서 일할 가능성이 높으며 ML 애플리케이션을 확장할 수 있어야 한다.

## 7.2 배치 예측 vs. 온라인 예측

시스템이 예측 결과를 생성해 최종 사용자에게 서빙하는 방법(배치 예측 혹은 온라인 예측)은 최종 사용자와 시스템에서 작업하는 개발자 모두에게 영향을 미친다.

온라인 예측은 예측에 대한 요청이 도착하는 즉시 예측이 생성되고 반환되는 경우이다. 온 디멘드 예측, 동기 예측이라고도 한다. (구글 번역에 영어 문장을 입력하는 즉시 프랑스어 번역문이 돌아온다.)

배치 예측은 예측이 주기적으로 혹은 트리거될 때마다 생성되는 경우이다. 비동기 예측이라고도 한다. (넷플릭스는 네 시간마다 모든 사용자에 대한 영화 추천을 생성하며 사용자가 넷플릭스에 로그인할 때 사전 계산된 추천을 가져와서 표시해준다.)

배치 예측에서는 배치 피처만 사용하며 온라인 예측에서는 배치 피처와 스트리밍 피처를 모두 사용할 수 있다. 음식 배달 플랫폼 도어대시에서 사용자의 주문에 대한 배송 시간을 추정하는데는 다음과 같은 피처가 필요하다.

- 배치 피처: 과거 이 음식점의 평균 음식 준비 시간
- 스트리밍 피처: 지난 10분 동안 해당 건 외에 들어온 주문 건수, 가용한 배달 인력 명수

온라인 예측이 배치 예측보다 비용과 성능 면에서 비효율적으로 생각하는 경우가 많다. 하지만 [3.6절 '배치 처리 vs. 스트림 처리'](2023-12-26-study-mlops-designing_ml_systems_3.md)에서 논의했듯이 이것이 반드시 맞지는 않다.

### 7.2.1 배치 예측에서 온라인 예측으로

온라인 예측은 모델이 예측을 생성하는 데 너무 오래 걸릴 수 있다는 문제가 있다.

배치 예측은 예측이 미리 계산되므로 모델이 예측을 생성하는 데 얼마나 오래 걸릴지 걱정할 필요가 없다. 예측을 많이 생성하되 결과가 즉시 필요하지 않을 때 유용하다. 하지만 모델이 사용자의 선호도 변화에 덜 민감하다는 점과 예측을 생성할 요청을 미리 알아야 한다는 점이 문제다.

배치 예측은 온라인 예측이 충분히 저렴하지 않거나 충분히 빠르지 않을 때 유용하다.

더 맞춤화되고 강력한 하드웨어가 등장하고 기술이 발전함에 따라 더 빠르고 저렴한 온라인 예측이 가능해지면서 온라인 예측이 기본이 됐다.

최근 몇 년 간 기업들은 배치 예측에서 온라인 예측으로 전환하기 위해 상당한 투자를 했다. 온라인 예측의 레이턴시 난제를 극복하려면 두 가지 구성 요소가 필요하다.

- (거의) 실시간 파이프라인. 수신 데이터로 작업하고, 필요에 따라 스트리밍 피처를 추출하고, 모델에 입력하고, 거의 실시간으로 예측을 반환한다. 실시간 전송과 스트림 계산 엔진이 있는 스트리밍 파이프라인이 도움이 된다.
- 최종 사용자가 만족할 만한 속도로 예측을 생성하는 모델. 대부분의 소비자 앱에서 밀리초 수준을 의미한다.

### 7.2.2 배치 파이프라인과 스트리밍 파이프라인의 통합

